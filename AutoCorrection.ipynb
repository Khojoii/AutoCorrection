{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2366385e-f20d-438f-90f9-6a1bc2ad08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4307243-dc26-4153-9b0c-310ac01c1e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'merciless', 'antipholus', 'canonize', 'fortunate', 'comprehend', 'subjugate', 'unveiling', 'vindicate', 'prosperous', 'resolute', 'prejudice', 'vulnerable', 'penitent', 'lad', 'ascendancy', 'labors', 'severe', 'waiver', 'swiftness', 'consent', 'injury', 'gratitude', 'wholesome', 'indigenous', 'diligent', 'manifestation', 'diverse', 'detour', 'unite', 'delightful', 'faded', 'reliable', 'sublime', 'wip', 'sorrow', 'ambiguous', 'unruly', 'legitimate', 'scattered', 'discretion', 'gracious', 'humility', 'reassure', 'ambition', 'transgress', 'compliant', 'drift', 'adversary', 'frivolous', 'affection', 'quarrel', 'pleasure', 'persist', 'resistant', 'resilience', 'overcome', 'contemplate', 'bereft', 'exemplary', 'defiant', 'innovative', 'mourn', 'unmistakable', 'apprehensive', 'infinite', 'illuminate', 'ramification', 'eliminate', 'distilled', 'reflective', 'embellish', 'throwing', 'narrate', 'endeavour', 'lamentable', 'uncertain', 'revise', 'nurturing', 'profound', 'enthusiastic', 'quince', 'inconvenience', 'rigorous', 'obligation', 'imminent', 'revenue', 'companion', 'carrying', 'aggressive', 'deliberate', 'actual', 'melancholy', 'radiant', 'ruminate', 'serenity', 'profuse', 'inconsequential', 'recapitulate', 'ongles', 'frightening', 'destructive', 'halter', 'insatiable', 'grievance', 'tender', 'ravage', 'timid', 'misplaced', 'fortune'}\n"
     ]
    }
   ],
   "source": [
    "def process_data(file_name):\n",
    "    words = []\n",
    "    with open(file_name) as f:\n",
    "        file_name_data = f.read()\n",
    "    file_name_data = file_name_data.lower()\n",
    "    words = re.findall(r'\\w+', file_name_data)  \n",
    "    return words\n",
    "\n",
    "word_l = process_data('auto.txt') \n",
    "vocab = set(word_l)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "328471d5-4df9-4c0e-9e48-03cad168a409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'overcome': 2, 'legitimate': 1, 'canonize': 1, 'unruly': 1, 'lad': 1, 'tender': 1, 'labors': 1, 'actual': 1, 'antipholus': 1, 'halter': 1, 'throwing': 1, 'quince': 1, 'ongles': 1, 'faded': 1, 'wip': 1, 'swiftness': 1, 'subjugate': 1, 'endeavour': 1, 'melancholy': 1, 'inconsequential': 1, 'serenity': 1, 'quarrel': 1, 'distilled': 1, 'ramification': 1, 'resilience': 1, 'ravage': 1, 'indigenous': 1, 'waiver': 1, 'enthusiastic': 1, 'frivolous': 1, 'apprehensive': 1, 'obligation': 1, 'carrying': 1, 'misplaced': 1, 'imminent': 1, 'delightful': 1, 'prosperous': 1, 'insatiable': 1, 'prejudice': 1, 'companion': 1, 'revenue': 1, 'inconvenience': 1, 'grievance': 1, 'deliberate': 1, 'adversary': 1, 'sorrow': 1, 'profuse': 1, 'consent': 1, 'ambition': 1, 'lamentable': 1, 'transgress': 1, 'reflective': 1, 'discretion': 1, 'injury': 1, 'mourn': 1, 'persist': 1, 'destructive': 1, 'detour': 1, 'severe': 1, 'innovative': 1, 'uncertain': 1, 'aggressive': 1, 'timid': 1, 'ascendancy': 1, 'fortune': 1, 'profound': 1, 'manifestation': 1, 'ambiguous': 1, 'penitent': 1, 'vulnerable': 1, 'reliable': 1, 'diligent': 1, 'drift': 1, 'revise': 1, 'ruminate': 1, 'unmistakable': 1, 'fortunate': 1, 'defiant': 1, 'scattered': 1, 'unite': 1, 'resolute': 1, 'unveiling': 1, 'frightening': 1, 'embellish': 1, 'compliant': 1, 'rigorous': 1, 'infinite': 1, 'recapitulate': 1, 'narrate': 1, 'resistant': 1, 'bereft': 1, 'radiant': 1, 'exemplary': 1, 'comprehend': 1, 'eliminate': 1, 'sublime': 1, 'illuminate': 1, 'gratitude': 1, 'merciless': 1, 'affection': 1, 'contemplate': 1, 'humility': 1, 'gracious': 1, 'pleasure': 1, 'diverse': 1, 'wholesome': 1, 'nurturing': 1, 'reassure': 1, 'vindicate': 1})\n"
     ]
    }
   ],
   "source": [
    "def get_count(word_l):\n",
    "    word_count_dict = Counter(word_l)\n",
    "    return word_count_dict\n",
    "\n",
    "word_count_dict = get_count(word_l)\n",
    "print(word_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28ed9b1f-0fe6-4a4c-932a-66c6e9623d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'legitimate': 0.00909090909090909, 'canonize': 0.00909090909090909, 'unruly': 0.00909090909090909, 'lad': 0.00909090909090909, 'tender': 0.00909090909090909, 'labors': 0.00909090909090909, 'actual': 0.00909090909090909, 'antipholus': 0.00909090909090909, 'halter': 0.00909090909090909, 'throwing': 0.00909090909090909, 'quince': 0.00909090909090909, 'ongles': 0.00909090909090909, 'faded': 0.00909090909090909, 'wip': 0.00909090909090909, 'swiftness': 0.00909090909090909, 'subjugate': 0.00909090909090909, 'endeavour': 0.00909090909090909, 'melancholy': 0.00909090909090909, 'inconsequential': 0.00909090909090909, 'serenity': 0.00909090909090909, 'quarrel': 0.00909090909090909, 'distilled': 0.00909090909090909, 'ramification': 0.00909090909090909, 'resilience': 0.00909090909090909, 'overcome': 0.01818181818181818, 'ravage': 0.00909090909090909, 'indigenous': 0.00909090909090909, 'waiver': 0.00909090909090909, 'enthusiastic': 0.00909090909090909, 'frivolous': 0.00909090909090909, 'apprehensive': 0.00909090909090909, 'obligation': 0.00909090909090909, 'carrying': 0.00909090909090909, 'misplaced': 0.00909090909090909, 'imminent': 0.00909090909090909, 'delightful': 0.00909090909090909, 'prosperous': 0.00909090909090909, 'insatiable': 0.00909090909090909, 'prejudice': 0.00909090909090909, 'companion': 0.00909090909090909, 'revenue': 0.00909090909090909, 'inconvenience': 0.00909090909090909, 'grievance': 0.00909090909090909, 'deliberate': 0.00909090909090909, 'adversary': 0.00909090909090909, 'sorrow': 0.00909090909090909, 'profuse': 0.00909090909090909, 'consent': 0.00909090909090909, 'ambition': 0.00909090909090909, 'lamentable': 0.00909090909090909, 'transgress': 0.00909090909090909, 'reflective': 0.00909090909090909, 'discretion': 0.00909090909090909, 'injury': 0.00909090909090909, 'mourn': 0.00909090909090909, 'persist': 0.00909090909090909, 'destructive': 0.00909090909090909, 'detour': 0.00909090909090909, 'severe': 0.00909090909090909, 'innovative': 0.00909090909090909, 'uncertain': 0.00909090909090909, 'aggressive': 0.00909090909090909, 'timid': 0.00909090909090909, 'ascendancy': 0.00909090909090909, 'fortune': 0.00909090909090909, 'profound': 0.00909090909090909, 'manifestation': 0.00909090909090909, 'ambiguous': 0.00909090909090909, 'penitent': 0.00909090909090909, 'vulnerable': 0.00909090909090909, 'reliable': 0.00909090909090909, 'diligent': 0.00909090909090909, 'drift': 0.00909090909090909, 'revise': 0.00909090909090909, 'ruminate': 0.00909090909090909, 'unmistakable': 0.00909090909090909, 'fortunate': 0.00909090909090909, 'defiant': 0.00909090909090909, 'scattered': 0.00909090909090909, 'unite': 0.00909090909090909, 'resolute': 0.00909090909090909, 'unveiling': 0.00909090909090909, 'frightening': 0.00909090909090909, 'embellish': 0.00909090909090909, 'compliant': 0.00909090909090909, 'rigorous': 0.00909090909090909, 'infinite': 0.00909090909090909, 'recapitulate': 0.00909090909090909, 'narrate': 0.00909090909090909, 'resistant': 0.00909090909090909, 'bereft': 0.00909090909090909, 'radiant': 0.00909090909090909, 'exemplary': 0.00909090909090909, 'comprehend': 0.00909090909090909, 'eliminate': 0.00909090909090909, 'sublime': 0.00909090909090909, 'illuminate': 0.00909090909090909, 'gratitude': 0.00909090909090909, 'merciless': 0.00909090909090909, 'affection': 0.00909090909090909, 'contemplate': 0.00909090909090909, 'humility': 0.00909090909090909, 'gracious': 0.00909090909090909, 'pleasure': 0.00909090909090909, 'diverse': 0.00909090909090909, 'wholesome': 0.00909090909090909, 'nurturing': 0.00909090909090909, 'reassure': 0.00909090909090909, 'vindicate': 0.00909090909090909}\n"
     ]
    }
   ],
   "source": [
    "def get_probs(word_count_dict):\n",
    "    probs = {} \n",
    "    m = sum(word_count_dict.values())\n",
    "    for key in word_count_dict:\n",
    "        probs[key] = word_count_dict[key] / m\n",
    "    return probs\n",
    "\n",
    "probs = get_probs(word_count_dict)\n",
    "print(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3227fac-5146-46e3-a48f-fb52db6ac295",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letter(word):\n",
    "    delete_l = []\n",
    "    split_l = []\n",
    "    \n",
    "    for i in range(len(word)):\n",
    "        split_l.append([word[:i], word[i:]])\n",
    "    for a, b in split_l:\n",
    "        delete_l.append(a + b[1:])\n",
    "    return delete_l\n",
    "\n",
    "def switch_letter(word):\n",
    "    switch_l = []\n",
    "    split_l = []\n",
    "    for c in range(len(word)):\n",
    "        split_l.append([word[:c], word[c:]])\n",
    "    switch_l = [a + b[1] + b[0] + b[2:] for a, b in split_l if len(b) >= 2]\n",
    "    return switch_l\n",
    "\n",
    "def replace_letter(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    replace_l = []\n",
    "    split_l = []\n",
    "    for c in range(len(word)):\n",
    "        split_l.append((word[0:c], word[c:]))\n",
    "    replace_l = [a + l + (b[1:] if len(b) > 1 else '') for a, b in split_l if b for l in letters]\n",
    "    replace_set = set(replace_l)\n",
    "    replace_set.discard(word)  # از `remove` به `discard` تغییر داده شد تا خطا ندهد\n",
    "    replace_l = sorted(list(replace_set))\n",
    "    return replace_l\n",
    "\n",
    "def insert_letter(word):\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    insert_l = []\n",
    "    split_l = []\n",
    "    for c in range(len(word) + 1):\n",
    "        split_l.append((word[0:c], word[c:]))\n",
    "    insert_l = [a + l + b for a, b in split_l for l in letters]\n",
    "    return insert_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3718c990-7b8b-4064-a1fc-3fd4ed806635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_one_letter(word, allow_switches=True):\n",
    "    edit_one_set = set()\n",
    "    edit_one_set.update(delete_letter(word))\n",
    "    \n",
    "    if allow_switches:\n",
    "        edit_one_set.update(switch_letter(word))\n",
    "    \n",
    "    edit_one_set.update(replace_letter(word))\n",
    "    edit_one_set.update(insert_letter(word))\n",
    "    \n",
    "    return edit_one_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f632dc7-f838-462e-a97a-3b72018911db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_two_letters(word, allow_switches=True):\n",
    "    edit_two_set = set()\n",
    "    edit_one = edit_one_letter(word, allow_switches=allow_switches)\n",
    "    \n",
    "    for w in edit_one:\n",
    "        if w:\n",
    "            edit_two = edit_one_letter(w, allow_switches=allow_switches)\n",
    "            edit_two_set.update(edit_two)\n",
    "    return edit_two_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b1bbe4e-b9f8-43d6-a087-ad0c073f5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrections(word, probs, vocab, n=2):\n",
    "    suggestions = (\n",
    "        [word] if word in vocab else\n",
    "        list(edit_one_letter(word).intersection(vocab)) or\n",
    "        list(edit_two_letters(word).intersection(vocab)))\n",
    "    \n",
    "    n_best = [[s, probs[s]] for s in sorted(suggestions, key=lambda x: probs.get(x, 0), reverse=True)[:n]]\n",
    "    \n",
    "    return n_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aeb7b365-0eb3-4e17-972e-e8433840eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_word = 'sen'\n",
    "tmp_corrections = get_corrections(my_word, probs, vocab, 2)\n",
    "\n",
    "for i, word_prob in enumerate(tmp_corrections):\n",
    "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2c34a-45d9-469c-88a2-b7b6b05ef36c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
